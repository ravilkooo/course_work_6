# Сравнение и анализ алгоритмов генерации изображений нейросетевыми методами

В данной курсовой работе исследуется и реализуется генеративная модель на основе методов диффузии для генерации изображений. Модель использует современные методы глубокого обучения и архитектурные решения, чтобы создавать высококачественные изображения. Работа включает в себя реализацию данной модели, а также подробное описание алгоритмов и методов, используемых в процессе обучения и генерации.

## Постановка задачи
Целью данной курсовой работы является создание генеративной модели, способной генерировать изображения, которые могли бы быть непроизвольными, но при этом сохраняли бы натуральный стиль и качество. Для этого формулируется задачу обучения глубокой модели, которая обучается находить две компоненты в каждом сгенерированном изображении: шум и сигнал. Входной шум представлен как случайное изображение, а сигнал - как реальное изображение. Обучаемая модель разделяет шум и сигнал, что позволяет ей генерировать изображения.

В процессе обучения модель корректируется так, чтобы минимизировать ошибку между исходными изображениями и сгенерированными изображениями, где ошибка измеряется в виде средней абсолютной разницы между пиксельными значениями.

Качество генерации оценивается с использованием метрики Kernel Inception Distance (KID). Метрика KID измеряет разницу между сгенерированными и обучающими распределениями в пространстве представлений нейронной сети InceptionV3, предварительно обученной на ImageNet. Для метрики используется представление именно в таком пространстве, потому что InceptionV3 - универсальная сеть, предварительно обученная на крупном и разнообразном наборе данных ImageNet. Она имеет обширные знания о различных объектах и стилях визуального мира. Это делает ее хорошим выбором для извлечения признаков из изображений.

Вместо того, чтобы сравнивать изображения непосредственно, KID сравнивает представления этих изображений в пространстве InceptionV3. Это позволяет учесть сходство между изображениями на более абстрактном уровне, что часто более информативно для задачи оценки качества генерации.

Пусть:
- ${Noise}(i)$ - преобразование, накладывающее шум на изображение $i$
- ${Denoise}(i; W)$ - преобразование, восстанавливающее зашумлённое изображение $i$. $W$ - набор параметров модели.
- $I_r$ - множество реальных изображений,
- $I_N = {Noise}(I_r)$ - множество реальных изображений, после наложения шума.
- $I_g = {Denoise}(I_N)$ - множество сгенерированных изображений, т.е. восстановленных зашумленных изображений
- $\phi(x)$ - функция, отображающая изображения в представления в пространстве *InceptionV3*,
- $k(\xi, \eta)$ - функция ядра между представлениями $\xi$ и $\eta$, где
  >$$k(\xi, \eta) = \left(\frac{1}{d}\xi^{T}\eta + 1\right)^3$$
  и $d$ - размерность представлений.

Тогда метрика *Kernel Inception Distance (KID)* между $I_r$ и $I_g$ определяется следующим образом:
> $$KID(I_r, I_g) = \frac{1}{n^2} \sum_{i=1}^{n} \sum_{j=1}^{n} k(\phi(x_i), \phi(x_j)) - \frac{2}{n^2} \sum_{i=1}^{n} \sum_{j=1}^{n} k(\phi(x_i), \phi(y_j)) + \frac{1}{n^2} \sum_{i=1}^{n} \sum_{j=1}^{n} k(\phi(y_i), \phi(y_j))$$
где:
- $n$ - количество элементов в каждом из множеств $I_r$ и $I_g$,
- $\phi(x_i)$ и $\phi(x_j)$ - представления реальных изображений,
- $\phi(y_i)$ и $\phi(y_j)$ - представления сгенерированных изображений,
- $k(\cdot, \cdot)$ - функция ядра, как описано выше.

Теперь задача формулируется следующим образом: найти параметры $W$ модели Denoise, при которых метрика *KID* будет минимальна:
>$$W^* = \argmin_W KID(I_r, \text{Denoise}(\text{Noise}(I_r); W))$$

## Теоретическая часть
* Генеративные модели
* Про шум (диффузию)
* Про метрики
---
### Генеративные модели

Генеративные модели представляют собой класс алгоритмов машинного обучения, целью которых является моделирование и генерация данных, которые похожи на обучающие данные. Важной характеристикой генеративных моделей является их способность создавать новые образцы данных на основе структуры и закономерностей, выявленных в исходных данных. Эти модели имеют широкий спектр применений в таких областях, как компьютерное зрение, обработка естественного языка и искусственный интеллект. Важно отметить, что генеративные модели являются ключевым инструментом в сферах, где требуется создание новых данных, которые могли бы быть реалистичными и полезными.

Примеры генеративных моделей:

1) Генеративные состязательные сети (GAN): GAN - это один из наиболее известных и распространнёных классов генеративных моделей. Он состоит из двух нейронных сетей, генератора и дискриминатора, которые соревнуются друг с другом. Генератор создает данные, а дискриминатор оценивает, насколько они реалистичны. GAN широко используются в генерации изображений, видео и в обработке звука. Например, они могут использоваться для генерации картин, создания реалистичных фотографий лиц или для улучшения качества фотографий.

2) Вариационные автокодировщики (VAE): VAE - это другой класс генеративных моделей, который работает на основе автокодировщиков. Они способны не только генерировать данные, но и выполнять семантическую интерполяцию между образцами. Например, VAE могут быть использованы для генерации новых лиц, преобразования стилей изображений или генерации текстовых описаний изображений.

Генеративные модели имеют широкий спектр практических применений. Вот некоторые из них:

1) Генерация контента: Генеративные модели могут использоваться для создания контента, такого как изображения, музыка, тексты и видео. Например, они могут генерировать изображения для веб-дизайна, создавать музыку, адаптированную к настроению слушателя, писать тексты.

2) Увеличение объёма данных: Генеративные модели могут быть использованы для увеличения объема обучающих данных. Например, в области компьютерного зрения, они могут генерировать дополнительные изображения для обучения моделей распознавания объектов.

3) Улучшение данных: Модели, такие как GAN, могут использоваться для улучшения качества существующих данных. Это может включать в себя увеличение разрешения изображений, устранение шума или улучшение деталей.

4) Семантическая интерполяция: Генеративные модели могут выполнять семантическую интерполяцию между образцами. Например, они могут создавать плавные переходы между изображениями разных стилей или содержания.

5) Генерация данных для исследований: Генеративные модели могут использоваться для создания данных в научных исследованиях. Например, они могут генерировать синтетические данные для исследований в области медицины, физики или других дисциплин.

#### Denoising Diffusion Implicit Model (DDIM)

Denoising Diffusion Implicit Model (DDIM) - это относительно новая генеративная модель. DDIM основан на диффузии, статистическом процессе, который моделирует распространение шума в данных. Основная идея DDIM заключается в обучении модели постепенно очищать (декодировать) данные от шума, создавая реалистичные образцы. DDIM может быть использован для генерации изображений, видео, звуков и других типов данных.

### Модель шума и дуффузии

Шум - представляет собой случайные колебания в сигнале или измерении, которые могут оказывать влияние на точность и качество данных. Математически шум описывается как случайный сигнал, который добавляется к основному сигналу.

#### Получение зашумленных изображений

В случае Denoising Diffusion Implicit Model (DDIM), зашумление изображений происходит путем применения процесса диффузии.

Процесс диффузии в данном контексте можно представить как последовательное увеличение уровня шума в изображении.

Шум в данной работе имеет случайную природу и подчиняется нормальному закону распределения.
> $$noise \sim \mathcal{N}(0,1)$$
(1)

Предварительно все изображаения нормализованны так, чтобы среднее значение пикселей равно 0, а дисперсия равна 1.

> $$\mu(image) = 0$$
> $$d(image) = 1$$
(2)

Зашумленное изображение $noisy\_image$ представляет собой взвешенную сумму исходного сигнала (изображения) $image$ и шума $noise$:

> $$noisy\_image = signal\_rate * image + noise\_rate * noise,$$
(3)
 где
> $$signal\_rate * signal\_rate + noise\_rate * noise\_rate = 1$$
(4)

$signal\_rate$ - уровень исходного сигнала, $noise\_rate$ - уровень  шума.

Так как случайные шумы (стандартное нормальное распределение) и изображения (нормализованные) оба имеют нулевое среднее и единичное стандартное отклонение, зашумленные изображения всегда имеют единичную дисперсию, так же, как и их нешумные компоненты. Таким образом:

> $$\mu(noisy\_image) = 0$$
> $$d(noisy\_image) = 1$$
(5)

#### Диффузионное расписание (Diffusion schedule)

Предполагается что диффузия происходит за единичное время в нескольких этапов. В нулевой момент времени уровень исходного сигнала равен ноль, а уровень шума - 0: $signal\_rate = 1$, $noise\_rate = 0$. В конце ($t = 1$) - наоборот: $signal\_rate = 0$, $noise\_rate = 1$. Для вычисления уровня каждого сигнала в зашумленном изображении в промежуточные моменты времени используется специальная функция - *диффузионное расписание* ($DS$ - diffusion schedule).

$DS$ выдает два значения: скорость шума ($noise\_rate$) и скорость сигнала ($signal\_rate$).

В данной работе используется упрощенная непрерывная версия косинусного расписания, которое широко применяется в литературе [нужны ссылочки].



---


Таким образом, вторая глава подчеркивает важность понимания математической природы шума и процесса диффузии, используемых в данной работе. Также обсуждается диффузионное расписание и его роль в определении уровня шума и сигнала в зашумленных изображениях.
---

## Практическая часть
* Модель
  * Архитектура, слои
  * Методы, как именно она получает очищенное изображение, что на выходе
  * Мб какие-нибудь глобальные параметры

* Датасеты
* Результаты работы
