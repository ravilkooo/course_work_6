# Сравнение и анализ алгоритмов генерации изображений нейросетевыми методами

В данной курсовой работе исследуется и реализуется генеративная модель на основе методов диффузии для генерации изображений. Модель использует современные методы глубокого обучения и архитектурные решения, чтобы создавать высококачественные изображения. Работа включает в себя реализацию данной модели, а также подробное описание алгоритмов и методов, используемых в процессе обучения и генерации.

## Постановка задачи
Целью данной курсовой работы является создание генеративной модели, способной генерировать изображения, которые могли бы быть непроизвольными, но при этом сохраняли бы натуральный стиль и качество. Для этого формулируется задачу обучения глубокой модели, которая обучается находить две компоненты в каждом сгенерированном изображении: шум и сигнал. Входной шум представлен как случайное изображение, а сигнал - как реальное изображение. Обучаемая модель разделяет шум и сигнал, что позволяет ей генерировать изображения.

В процессе обучения модель корректируется так, чтобы минимизировать ошибку между исходными изображениями и сгенерированными изображениями, где ошибка измеряется в виде средней абсолютной разницы между пиксельными значениями.

Качество генерации оценивается с использованием метрики Kernel Inception Distance (KID). Метрика KID измеряет разницу между сгенерированными и обучающими распределениями в пространстве представлений нейронной сети InceptionV3, предварительно обученной на ImageNet. Для метрики используется представление именно в таком пространстве, потому что InceptionV3 - универсальная сеть, предварительно обученная на крупном и разнообразном наборе данных ImageNet. Она имеет обширные знания о различных объектах и стилях визуального мира. Это делает ее хорошим выбором для извлечения признаков из изображений.

Вместо того, чтобы сравнивать изображения непосредственно, KID сравнивает представления этих изображений в пространстве InceptionV3. Это позволяет учесть сходство между изображениями на более абстрактном уровне, что часто более информативно для задачи оценки качества генерации.

Пусть:
- ${Noise}(i)$ - преобразование, накладывающее шум на изображение $i$
- ${Denoise}(i; W)$ - преобразование, восстанавливающее зашумлённое изображение $i$. $W$ - набор параметров модели.
- $I_r$ - множество реальных изображений,
- $I_N = {Noise}(I_r)$ - множество реальных изображений, после наложения шума.
- $I_g = {Denoise}(I_N)$ - множество сгенерированных изображений, т.е. восстановленных зашумленных изображений
- $\phi(x)$ - функция, отображающая изображения в представления в пространстве *InceptionV3*,
- $k(\xi, \eta)$ - функция ядра между представлениями $\xi$ и $\eta$, где
  >$$k(\xi, \eta) = \left(\frac{1}{d}\xi^{T}\eta + 1\right)^3$$
  и $d$ - размерность представлений.

Тогда метрика *Kernel Inception Distance (KID)* между $I_r$ и $I_g$ определяется следующим образом:
> $$KID(I_r, I_g) = \frac{1}{n^2} \sum_{i=1}^{n} \sum_{j=1}^{n} k(\phi(x_i), \phi(x_j)) - \frac{2}{n^2} \sum_{i=1}^{n} \sum_{j=1}^{n} k(\phi(x_i), \phi(y_j)) + \frac{1}{n^2} \sum_{i=1}^{n} \sum_{j=1}^{n} k(\phi(y_i), \phi(y_j))$$
где:
- $n$ - количество элементов в каждом из множеств $I_r$ и $I_g$,
- $\phi(x_i)$ и $\phi(x_j)$ - представления реальных изображений,
- $\phi(y_i)$ и $\phi(y_j)$ - представления сгенерированных изображений,
- $k(\cdot, \cdot)$ - функция ядра, как описано выше.

Теперь задача формулируется следующим образом: найти параметры $W$ модели Denoise, при которых метрика *KID* будет минимальна:
>$$W^* = \argmin_W KID(I_r, \text{Denoise}(\text{Noise}(I_r); W))$$

## 1. Теоретическая часть
* Генеративные модели
* Про шум (диффузию)
* Про метрики
---
### 1.1. Генеративные модели

Генеративные модели представляют собой класс алгоритмов машинного обучения, целью которых является моделирование и генерация данных, которые похожи на обучающие данные. Важной характеристикой генеративных моделей является их способность создавать новые образцы данных на основе структуры и закономерностей, выявленных в исходных данных. Эти модели имеют широкий спектр применений в таких областях, как компьютерное зрение, обработка естественного языка и искусственный интеллект. Важно отметить, что генеративные модели являются ключевым инструментом в сферах, где требуется создание новых данных, которые могли бы быть реалистичными и полезными.

Примеры генеративных моделей:

1) Генеративные состязательные сети (GAN): GAN - это один из наиболее известных и распространнёных классов генеративных моделей. Он состоит из двух нейронных сетей, генератора и дискриминатора, которые соревнуются друг с другом. Генератор создает данные, а дискриминатор оценивает, насколько они реалистичны. GAN широко используются в генерации изображений, видео и в обработке звука. Например, они могут использоваться для генерации картин, создания реалистичных фотографий лиц или для улучшения качества фотографий.

2) Вариационные автокодировщики (VAE): VAE - это другой класс генеративных моделей, который работает на основе автокодировщиков. Они способны не только генерировать данные, но и выполнять семантическую интерполяцию между образцами. Например, VAE могут быть использованы для генерации новых лиц, преобразования стилей изображений или генерации текстовых описаний изображений.

Генеративные модели имеют широкий спектр практических применений. Вот некоторые из них:

1) Генерация контента: Генеративные модели могут использоваться для создания контента, такого как изображения, музыка, тексты и видео. Например, они могут генерировать изображения для веб-дизайна, создавать музыку, адаптированную к настроению слушателя, писать тексты.

2) Увеличение объёма данных: Генеративные модели могут быть использованы для увеличения объема обучающих данных. Например, в области компьютерного зрения, они могут генерировать дополнительные изображения для обучения моделей распознавания объектов.

3) Улучшение данных: Модели, такие как GAN, могут использоваться для улучшения качества существующих данных. Это может включать в себя увеличение разрешения изображений, устранение шума или улучшение деталей.

4) Семантическая интерполяция: Генеративные модели могут выполнять семантическую интерполяцию между образцами. Например, они могут создавать плавные переходы между изображениями разных стилей или содержания.

5) Генерация данных для исследований: Генеративные модели могут использоваться для создания данных в научных исследованиях. Например, они могут генерировать синтетические данные для исследований в области медицины, физики или других дисциплин.

#### Denoising Diffusion Implicit Model (DDIM)

Denoising Diffusion Implicit Model (DDIM) - это относительно новая генеративная модель. DDIM основан на диффузии, статистическом процессе, который моделирует распространение шума в данных. Основная идея DDIM заключается в обучении модели постепенно очищать (декодировать) данные от шума, создавая реалистичные образцы. DDIM может быть использован для генерации изображений, видео, звуков и других типов данных.

### 1.2. Модель шума и дуффузии

Шум - представляет собой случайные колебания в сигнале или измерении, которые могут оказывать влияние на точность и качество данных. Математически шум описывается как случайный сигнал, который добавляется к основному сигналу.

#### Получение зашумленных изображений

В случае Denoising Diffusion Implicit Model (DDIM), зашумление изображений происходит путем применения процесса диффузии.

Процесс диффузии в данном контексте можно представить как последовательное увеличение уровня шума в изображении.

Шум в данной работе имеет случайную природу и подчиняется нормальному закону распределения.
> $$noise \sim \mathcal{N}(0,1)$$
(1)

Предварительно все изображаения нормализованны так, чтобы среднее значение пикселей равно 0, а дисперсия равна 1.

> $$\mu(image) = 0$$
> $$d(image) = 1$$
(2)

Зашумленное изображение $noisy\_ {image}$ представляет собой взвешенную сумму исходного сигнала (изображения) $image$ и шума $noise$:

> $$noisy\_ {image} = signal\_ {rate} * image + noise\_ {rate} * noise,$$
(3)
 где
> $$signal\_ {rate}^2 + noise\_ {rate}^2 = 1$$
(4)

$signal\_ {rate}$ - уровень исходного сигнала, $noise\_ {rate}$ - уровень  шума.

Так как случайные шумы (стандартное нормальное распределение) и изображения (нормализованные) оба имеют нулевое среднее и единичное стандартное отклонение, зашумленные изображения всегда имеют единичную дисперсию, так же, как и их нешумные компоненты. Таким образом:

> $$\mu(noisy\_ {image}) = 0$$
> $$d(noisy\_ {image}) = 1$$
#### Диффузионное расписание (Diffusion schedule)

Предполагается что диффузия происходит за единичное время в нескольких этапов. В нулевой момент времени уровень исходного сигнала равен ноль, а уровень шума - 0: $signal\_ {rate} = 1$, $noise\_ {rate} = 0$. В конце ($t = 1$) - наоборот: $signal\_ {rate} = 0$, $noise\_ {rate} = 1$. Для вычисления уровня каждого сигнала в зашумленном изображении в промежуточные моменты времени используется специальная функция - *диффузионное расписание* ($DS$ - diffusion schedule).

$DS$ выдает два значения: скорость шума ($noise\_ {rate}$) и скорость сигнала ($signal\_ {rate}$).

В данной работе используется упрощенная непрерывная версия косинусного расписания, которое широко применяется в литературе [нужны ссылочки]. В этой модели уровни сингалов определяются следующим образом:
> $$signal\_ {rate}_i = cos(diff\_ {angle}_i),$$
> $$noise\_ {rate}_i = sin(diff\_ {angle}_i),$$
(6)

где
> $${diff\_ {angle}}_i = start\_ {angle} + (end\_ {angle} - start\_ {angle}) \frac {i}{diff\_ {steps}},$$
> $$i = 1,...,diff\_ {steps}$$
> $$start\_ {angle} = arccos(min\_ {signal}\_ {rate})$$
> $$end\_ {angle} = arccos(max\_ {signal}\_ {rate})$$
(7)

$diff\_ {steps}$ - количествов шагов диффузии. Параметры $min \_ {signal} \_ {rate}$ и $max \_ {signal} \_ {rate}$ выбираются близкими к нулю и единице соответсвенно и подбираются экспериментальным путём.

### 1.3. Оценка качества генеративных моделей

#### Kernel Inception Distance (KID)

Метрика *Kernel Inception Distance* (KID) представляет собой меру различия между сгенерированными изображениями и обучающими данными в пространстве представлений, созданном моделью InceptionV3, предварительно обученной на наборе данных ImageNet. Метрика KID является альтернативой популярной метрике *Frechet Inception Distance* (FID) и обеспечивает оценку качества генерации изображений. Преимущество метрики KID заключается в более простой реализации, меньшей вычислительной сложности, также она лучше подходит для небольших датасетов [СТАТЬЯ] который используются в нашем случае.

Метрика KID между двумя множествами векторов $\{\xi_i\}^n_{i=1}$, $\{\eta_i\}^n_{i=1}$ определяется следующей формулой:
> $$KID = \frac{1}{n^2} \sum_{i=1}^{n} \sum_{j=1}^{n} k(\xi_i, \xi_j) - \frac{2}{n^2} \sum_{i=1}^{n} \sum_{j=1}^{n} k(\xi_i, \eta_j) + \frac{1}{n^2} \sum_{i=1}^{n} \sum_{j=1}^{n} k(\eta_i, \eta_j),$$
где
$k(\xi, \eta) = \left(\frac{1}{d}\xi^{T}\eta + 1\right)^3$ - функция ядра, $d$ - размерность векторов.

#### Maximum Mean Discrepancy (MMD)

KID является эмпирической оценкой *максимального среднего несоответсвия* (MMD - maximum mean discrepancy), которое измеряет расстояние между двумя распределениями в пространстве RKHS. RKHS - это гильбертово пространство функций[СТАТЬЯ], связанных с определенной функцией ядра (kernel function). Понятие функции ядра играет важную роль в оценке KID, так как ядро определяет, как функции представления связаны в RKHS. KID в свою очередь является эмерической оценкой на основе экземпляров двух распределений.

MMD и KID вычисляются с использованием kernel functions, которые представляют собой функции, оценивающие сходство между элементами двух распределений. Основная идея заключается в том, что MMD будет равно нулю, только если оба распределения совпадают. Это свойство делает MMD полезным инструментом для оценки качества генерации изображений.

Таким образом, KID обеспечивает оценку качества генерации изображений, используя математические концепции MMD, kernel functions и RKHS. Эти инструменты позволяют количественно измерить различие между сгенерированными и реальными данными и оценить качество генеративных моделей.


## 2. Практическая часть


### 2.1. Программное обеспчение

Код программы был реализован на языке Python, с использованием специализированной библиотеки Tensorflow. Она предоставляет инструменты для определения сложных нейронных сетей и эффективного обучения.

### 2.2. Подготовка данных

Для проведения экспериментов и обучения генеративной модели были использован наборы данных Oxford Flowers 102 и Caltech-UCSD Birds 200 (CUB-200). Oxford Flowers 102 представляет собой разнообразный собранный изображений природы и содержит около 8,000 изображений цветов. CUB-200 - набор данных изображений с фотографиями 200 видов птиц (в основном североамериканских), в наборе данных 2011 года содердится 11 788 изображений.

Для обеспечения адекватного и сбалансированного набора данных для обучения модели, были выполнены следующие этапы:

- Разбиение данных

  Исходный набор данных был подвергнут разделению на тренировочную (80% данных) и валидационную (20% данных) выборки. Этот процесс разделения данных был выполнен с использованием Tensorflow Datasets slicing API. Это позволило устранить проблему несбалансированности и обеспечить адекватное распределение данных для обучения и оценки модели.

- Препроцессинг с использованием центральных обрезок:
  В качестве части процесса предобработки данных были выполнены центральные обрезки изображений. Отбросывание неинформативной области изображения, может быть полезным для улучшения качества обучения модели.

- Нормализация:
  Для обеспечения стабильности обучения и улучшения результатов модели, данные были нормализованы. Тажкже этого требует используемая модель диффузии. Вместо перевода значений в диапазон [-1, 1], как это делается обычно, было проведено нормализация данных, чтобы они имели среднее значение 0 и единичное стандартное отклонение.

### 2.3. Архитектура модели
